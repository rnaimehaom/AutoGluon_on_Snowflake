{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aca7b9a2-ae11-48f8-800d-08aecf325cd4",
   "metadata": {},
   "source": [
    "# Step 1.4 Define UDF and Predict\n",
    "\n",
    "Now that we have used AutoGluon to build the model, we now walk thru the steps to have this model\n",
    "deployed as a UDF. The UDF then can be called on input dataset to predict the label, based on unseen\n",
    "data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c22660f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image , Markdown\n",
    "from snowflake.snowpark.session import Session\n",
    "from snowflake.snowpark.types import * \n",
    "from snowflake.snowpark.functions import *\n",
    "import configparser\n",
    "\n",
    "PROJECT_HOME_DIR = '../../..'\n",
    "CONFIG_FL = f'{PROJECT_HOME_DIR}/config.ini'\n",
    "LOCAL_TEMP_DIR = f'{PROJECT_HOME_DIR}/temp'\n",
    "\n",
    "%run ./scripts/notebook_helpers.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fadfa9bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='#EAE3D2';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Initialize Snowpark session\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CURRENT_WAREHOUSE()</th>\n",
       "      <th>CURRENT_USER()</th>\n",
       "      <th>CURRENT_ROLE()</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LAB_WH</td>\n",
       "      <td>VSEKAR</td>\n",
       "      <td>DEV_BLOGGER</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  CURRENT_WAREHOUSE() CURRENT_USER() CURRENT_ROLE()\n",
       "0              LAB_WH         VSEKAR    DEV_BLOGGER"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Initialization\n",
    "set_cell_background('#EAE3D2')\n",
    "\n",
    "config = configparser.ConfigParser()\n",
    "sflk_session = None\n",
    "\n",
    "print(\" Initialize Snowpark session\")\n",
    "with open(CONFIG_FL) as f:\n",
    "    config.read(CONFIG_FL)\n",
    "    snow_conn_flpath =  f\"{PROJECT_HOME_DIR}/{config['DEFAULT']['connection_fl']}\"\n",
    "    \n",
    "    # ------------\n",
    "    # Connect to snowflake\n",
    "    with open(snow_conn_flpath) as conn_f:\n",
    "        snow_conn_info = json.load(conn_f)\n",
    "        sflk_session = Session.builder.configs(snow_conn_info).create()\n",
    "\n",
    "if(sflk_session == None):\n",
    "    raise(f'Unable to connect to snowflake. Validate connection information in file: {CONFIG_FL} ')\n",
    "\n",
    "df = sflk_session.sql('select current_warehouse(), current_user(), current_role();').to_pandas()\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ad79233",
   "metadata": {},
   "source": [
    "---\n",
    "## Define Prediction UDF\n",
    "\n",
    "We want to run predictions/inference, using the AutoGluon trained models, within Snowflake natively.\n",
    "Hence in the below steps we define the UDF (predict_occupancy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "501c7fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='#EAE3D2';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define prediction udf\n",
    "set_cell_background('#EAE3D2')\n",
    "\n",
    "from snowflake.snowpark.functions import pandas_udf\n",
    "\n",
    "target_db = config['DEFAULT']['db']\n",
    "target_schema = config['DEFAULT']['sch']\n",
    "stage = config['DEFAULT']['stage']\n",
    "tage = config['DEFAULT']['stage']\n",
    "stage_lib_dir = config['DEFAULT']['stage_lib_dir']\n",
    "stage_models_dir = config['DEFAULT']['stage_models_dir']\n",
    "\n",
    "\n",
    "imports_to_fn = [\n",
    "    f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon.core-0.5.2-py3-none-any.whl'''\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon.common-0.5.2-py3-none-any.whl'''\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon.extra-0.3.1-py3-none-any.whl'''\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon.features-0.5.2-py3-none-any.whl'''\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon.tabular-0.5.2-py3-none-any.whl'''\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_lib_dir}autogluon-0.5.2-py3-none-any.whl'''\n",
    "\n",
    "    ,f'''@{target_db}.{target_schema}.{stage}/{stage_models_dir}{config['DEFAULT']['ag_model_archive']}'''\n",
    "]\n",
    "\n",
    "predict_room_occupancy_udf = sflk_session.udf.register_from_file(\n",
    "    file_path=f'{PROJECT_HOME_DIR}/src/main/python/predict_room_occupancy.py'\n",
    "    \n",
    "    ,func_name='predict_occupancy'\n",
    "    ,return_type=IntegerType() \n",
    "    ,input_types=[StringType() ,FloatType() ,FloatType() ,FloatType() ,FloatType() ,FloatType()] #model_touse ,CO2 ,HUMIDITY ,LIGHT ,TEMPERATURE ,PIR\n",
    "\n",
    "    ,name=f'{target_db}.{target_schema}.predict_occupancy'\n",
    "    ,is_permanent = True ,replace = True\n",
    "    ,stage_location=f'@{target_db}.{target_schema}.{stage}/fnlib'\n",
    "    ,imports = imports_to_fn\n",
    "    ,packages = ['snowflake-snowpark-python' ,'requests' ,'tqdm' ,'scipy' \n",
    "        ,'scikit-learn' ,'boto3' ,'networkx' ,'pandas' ,'numpy']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97999ed5-c51d-47c4-a03e-5a30a5ccce2e",
   "metadata": {},
   "source": [
    "---\n",
    "## Prediction/Inference\n",
    "\n",
    "Now for the final step of demonstrating the inference using the UDF defined above. In the below SQL, we invoke the UDF defined above\n",
    "passing in the columns (which are the features). The UDF is implemented as a vectorized UDF, hence the columns are combined into a dataframe\n",
    "and sent into the UDF.\n",
    "\n",
    "We can ask AutoGluon to use specific model to use for the inference. However we cannot pass this as a single parameter. Hence we have to\n",
    "put into a column ('MODEL_TO_USE') and pass it to the UDF. This is because the Vectorized UDF which takes pandas dataframe as input cannot\n",
    "take additional parameters.\n",
    "\n",
    "__Reference:__\n",
    "- Doc:[Using Vectorized UDFs via the Python UDF Batch API](https://docs.snowflake.com/en/developer-guide/snowpark/python/creating-udfs.html#using-vectorized-udfs-via-the-python-udf-batch-api)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d553eb49-710f-4362-8ed5-d7c007756dde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='#EAE3D2';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <html> <body>\n",
       "        <h4> Queries </h4>\n",
       "        <pre style=\"background-color:honeydew\">\n",
       "        \n",
       "<b>Q: Can I use any of the models trained by AutoGluon?</b>\n",
       "\n",
       "A: Unfortunately <strong>NO</strong>. Not all models/algorithms can be used. The reason being that the 3rd party libraries (ex: autogluon.core-0.5.2-py3-none-any.whl)\n",
       "can be extracted and imported as long as there are no native components/libraries. <i><ins>CatBoost & NeuralNetFastAI</ins></i> are examples of algorithms that \n",
       "cannot be used.\n",
       "\n",
       "In the case of <i>CatBoost</i> it requires a native library '_catboost.so' that would not be able to be loaded. And in the case of <i>NeuralNetFastAI</i>\n",
       "it requires FastAI which has a dependency of MatPlotLib. The MatPlotLib uses a native library hence it cant be loaded.\n",
       "\n",
       "There are also certain algorithm that is not possible to use currently, for ex: <i><ins>NeuralNetTorch</ins></i> We need to use the PyTorch 1.12 version which is\n",
       "used by AutoGluon and not the one from Snowflake Anaconda channel, which is of version 1.10. The PyTorch library is 750MB+ in size, hence when we \n",
       "extract it we run out of disk space. Currently the temp folder, which is where we use for libraries locally, is limited to 500MB.\n",
       "\n",
       "<b>Q: What models have worked currently via the UDF?</b>\n",
       "\n",
       "A:  KNeighborsUnif ,KNeighborsDist ,ExtraTreesGini ,ExtraTreesEntr ,RandomForestGini ,RandomForestEntr\n",
       "\n",
       "<b>Q: What are the various models that AutoGluon currently supports?</b>\n",
       "\n",
       "A: Refer to doc <a href='https://auto.gluon.ai/stable/api/autogluon.tabular.models.html'>autogluon.tabular.models </a>\n",
       "\n",
       "\n",
       "        </pre>\n",
       "        </body> </html>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_cell_background('#EAE3D2')\n",
    "\n",
    "display_code(p_title='Queries' ,p_background_color='honeydew'\n",
    "       ,p_code=f'''\n",
    "<b>Q: Can I use any of the models trained by AutoGluon?</b>\n",
    "\n",
    "A: Unfortunately <strong>NO</strong>. Not all models/algorithms can be used. The reason being that the 3rd party libraries (ex: autogluon.core-0.5.2-py3-none-any.whl)\n",
    "can be extracted and imported as long as there are no native components/libraries. <i><ins>CatBoost & NeuralNetFastAI</ins></i> are examples of algorithms that \n",
    "cannot be used.\n",
    "\n",
    "In the case of <i>CatBoost</i> it requires a native library '_catboost.so' that would not be able to be loaded. And in the case of <i>NeuralNetFastAI</i>\n",
    "it requires FastAI which has a dependency of MatPlotLib. The MatPlotLib uses a native library hence it cant be loaded.\n",
    "\n",
    "There are also certain algorithm that is not possible to use currently, for ex: <i><ins>NeuralNetTorch</ins></i> We need to use the PyTorch 1.12 version which is\n",
    "used by AutoGluon and not the one from Snowflake Anaconda channel, which is of version 1.10. The PyTorch library is 750MB+ in size, hence when we \n",
    "extract it we run out of disk space. Currently the temp folder, which is where we use for libraries locally, is limited to 500MB.\n",
    "\n",
    "<b>Q: What models have worked currently via the UDF?</b>\n",
    "\n",
    "A:  KNeighborsUnif ,KNeighborsDist ,ExtraTreesGini ,ExtraTreesEntr ,RandomForestGini ,RandomForestEntr\n",
    "\n",
    "<b>Q: What are the various models that AutoGluon currently supports?</b>\n",
    "\n",
    "A: Refer to doc <a href='https://auto.gluon.ai/stable/api/autogluon.tabular.models.html'>autogluon.tabular.models </a>\n",
    "\n",
    "''')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac5276b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src onerror=\"var cell = this.closest('.jp-CodeCell');var editor = cell.querySelector('.jp-Editor');editor.style.background='#EAE3D2';this.parentNode.removeChild(this)\" style=\"display:none\">"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------\n",
      "|\"CO2\"  |\"HUMIDITY\"  |\"TEMPERATURE\"  |\"PIR\"  |\"MODEL_TOUSE\"   |\"PRED_VAL\"  |\n",
      "----------------------------------------------------------------------------\n",
      "|680.0  |54.48       |24.34          |23.0   |KNeighborsUnif  |1           |\n",
      "|680.0  |54.48       |24.34          |23.0   |KNeighborsUnif  |1           |\n",
      "|686.0  |54.48       |24.34          |22.0   |KNeighborsUnif  |1           |\n",
      "|686.0  |54.48       |24.34          |22.0   |KNeighborsUnif  |1           |\n",
      "|681.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "|684.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "|678.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "|675.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "|678.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "|670.0  |54.48       |24.34          |21.0   |KNeighborsUnif  |1           |\n",
      "----------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "set_cell_background('#EAE3D2')\n",
    "\n",
    "df = sflk_session.sql(\n",
    "        f''' \n",
    "        with base as (\n",
    "                select * from {target_db}.{target_schema}.sensor_measurements_imputed\n",
    "                limit 10000\n",
    "        )\n",
    "        select \n",
    "                CO2 ,HUMIDITY ,TEMPERATURE ,PIR\n",
    "                ,'KNeighborsUnif' as MODEL_TOUSE\n",
    "                ,{target_db}.{target_schema}.predict_occupancy(\"MODEL_TOUSE\" ,\"CO2\" ,\"HUMIDITY\" ,\"LIGHT\" ,\"TEMPERATURE\" ,\"PIR\") as pred_val\n",
    "                \n",
    "        from base\n",
    "        where PIR > 1\n",
    "        ''')\n",
    "\n",
    "df.show(max_width=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae05f80f",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff35858-91cf-4ad1-a361-37a161b37539",
   "metadata": {},
   "source": [
    "### Close out\n",
    "\n",
    "    With that we are finished this section of the demo setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf34e465-233f-4b98-abd6-25bbc4efe604",
   "metadata": {},
   "outputs": [],
   "source": [
    "sflk_session.close()\n",
    "print('Finished!!!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9f98284b1b77effdad8e825a9416e70aada8c9b829685ab62b26245ff3dd3a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
